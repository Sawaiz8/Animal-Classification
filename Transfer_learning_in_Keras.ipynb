{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sawaiz8/Animal-Classification/blob/Transfer-learning-VGG16-on-animal-classification/Transfer_learning_in_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d69e43f",
      "metadata": {
        "id": "7d69e43f"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle"
      ],
      "metadata": {
        "id": "Fo48WUvCdHrB"
      },
      "id": "Fo48WUvCdHrB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/\n",
        "!kaggle datasets download -d utkarshsaxenadn/animal-image-classification-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytaZ3OXgdH_4",
        "outputId": "ee322e13-a3ee-4737-caee-f59bc72095b3"
      },
      "id": "ytaZ3OXgdH_4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading animal-image-classification-dataset.zip to /content\n",
            "100% 1.60G/1.61G [00:09<00:00, 226MB/s]\n",
            "100% 1.61G/1.61G [00:09<00:00, 189MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/animal-image-classification-dataset.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "fVwdRYwQdadY"
      },
      "id": "fVwdRYwQdadY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af6dfeda",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "af6dfeda",
        "outputId": "09e8a724-a8b2-4edd-b867-97f768253557"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f97fd91",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f97fd91",
        "outputId": "1c2f00d8-2985-470c-9d0b-f895496d7c18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-17-ae932be897c3>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(tf.test.is_gpu_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1995311",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1995311",
        "outputId": "a41a6126-c01c-4bdc-b2de-57c23c5c0ab4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "681f8d9c",
      "metadata": {
        "id": "681f8d9c"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras import utils\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense,Flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bac8388",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bac8388",
        "outputId": "f6cad1bc-59ee-4389-d310-161661a48d5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "conv_base = VGG16(\n",
        "    weights = 'imagenet',\n",
        "    include_top = False,\n",
        "    input_shape = (150,150,3)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23296d34",
      "metadata": {
        "id": "23296d34"
      },
      "outputs": [],
      "source": [
        "from keras import Sequential\n",
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e22f5eee",
      "metadata": {
        "id": "e22f5eee"
      },
      "outputs": [],
      "source": [
        "model.add(conv_base)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256,activation = 'relu'))\n",
        "model.add(Dense(10, activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "596900d1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "596900d1",
        "outputId": "60c9c35a-2b31-4cc4-f0fc-afa002b5403f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               2097408   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,814,666\n",
            "Trainable params: 16,814,666\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5feeae40",
      "metadata": {
        "id": "5feeae40"
      },
      "outputs": [],
      "source": [
        "#Turn conv base trainable to false\n",
        "conv_base.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b81773a2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b81773a2",
        "outputId": "c3444bad-c2da-43c3-ce31-969ce0be599a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               2097408   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,814,666\n",
            "Trainable params: 2,099,978\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary() #check trainable parameter now"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "lst = ['Cat', 'Cow','Dog', 'Elephant', 'Gorilla', 'Hippo', 'Monkey', 'Panda', 'Tiger', 'Zebra']\n",
        "for i in range(10):\n",
        "  # Set the directory where the images are stored\n",
        "  directory = '/content/Animal-Data-V2/Data-V2/Training Data/' + lst[i]\n",
        "  # Iterate through all the files in the directory\n",
        "  for filename in os.listdir(directory):\n",
        "    # Check if the file is an image\n",
        "    if not (filename.endswith(\".jpeg\")):\n",
        "      # Open the image file\n",
        "      with Image.open(os.path.join(directory, filename)) as im:\n",
        "        im = im.convert('RGB')\n",
        "        # Convert the image to PNG format\n",
        "        im.save(os.path.join(directory, filename.rsplit(\".\", 1)[0] + \".jpeg\"))\n",
        "        # Delete the original image\n",
        "        os.remove(os.path.join(directory, filename))"
      ],
      "metadata": {
        "id": "p-DRFmIMeGLF"
      },
      "id": "p-DRFmIMeGLF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1441bef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1441bef",
        "outputId": "ee7005f2-6a9b-4b83-dafc-b2e18d828b8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 19598 files belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "train_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = '/content/Animal-Data-V2/Data-V2/Training Data',\n",
        "    labels = 'inferred',\n",
        "    label_mode = 'int',\n",
        "    batch_size = 32,\n",
        "    image_size = (150,150)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2130d0ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2130d0ac",
        "outputId": "b518a0fa-42e1-40f8-b55c-3df97f9612c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 838 files belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "validation_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = '/content/Animal-Data-V2/Data-V2/Validation Data',\n",
        "    labels = 'inferred',\n",
        "    label_mode = 'int',\n",
        "    batch_size = 32,\n",
        "    image_size = (150,150)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c60055b3",
      "metadata": {
        "id": "c60055b3"
      },
      "outputs": [],
      "source": [
        "def process(image,label):\n",
        "    image  = tf.cast(image/255, tf.float32)\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b454bf2",
      "metadata": {
        "id": "0b454bf2"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(process)\n",
        "validation_ds = validation_ds.map(process)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad650635",
      "metadata": {
        "id": "ad650635"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = 'adam', loss= 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74080b9f",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74080b9f",
        "outputId": "919f9947-2bf5-4eaa-b05d-837c1dbd33e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "613/613 [==============================] - 56s 91ms/step - loss: 0.0969 - accuracy: 0.9691 - val_loss: 0.9447 - val_accuracy: 0.8067\n",
            "Epoch 2/4\n",
            "613/613 [==============================] - 57s 93ms/step - loss: 0.0903 - accuracy: 0.9704 - val_loss: 1.3900 - val_accuracy: 0.7530\n",
            "Epoch 3/4\n",
            "613/613 [==============================] - 55s 89ms/step - loss: 0.0788 - accuracy: 0.9736 - val_loss: 1.1165 - val_accuracy: 0.7828\n",
            "Epoch 4/4\n",
            "613/613 [==============================] - 56s 91ms/step - loss: 0.0689 - accuracy: 0.9774 - val_loss: 1.2181 - val_accuracy: 0.7947\n"
          ]
        }
      ],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    history = model.fit(train_ds, epochs = 4, validation_data = validation_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72c376d0",
      "metadata": {
        "id": "72c376d0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "lst = ['Cat', 'Cow','Dog', 'Elephant', 'Gorilla', 'Hippo', 'Monkey', 'Panda', 'Tiger', 'Zebra']\n",
        "for i in range(10)\n",
        "  # Set the directory where the images are stored\n",
        "  directory = 'Animal-Data-V2/Data-V2/Validation Data/' + lst[i]\n",
        "  # Iterate through all the files in the directory\n",
        "  for filename in os.listdir(directory):\n",
        "    # Check if the file is an image\n",
        "    if not (filename.endswith(\".jpeg\")):\n",
        "      # Open the image file\n",
        "      with Image.open(os.path.join(directory, filename)) as im:\n",
        "        im = im.convert('RGB')\n",
        "        # Convert the image to PNG format\n",
        "        im.save(os.path.join(directory, filename.rsplit(\".\", 1)[0] + \".jpeg\"))\n",
        "        # Delete the original image\n",
        "        os.remove(os.path.join(directory, filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e29a9735",
      "metadata": {
        "id": "e29a9735"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import imghdr\n",
        "\n",
        "data_dir = \"Animal-Data-V2/Data-V2/Validation Data/Cat\"\n",
        "image_extensions = [\".png\", \".jpg\"]  # add there all your images file extensions\n",
        "\n",
        "img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\n",
        "for filepath in Path(data_dir).rglob(\"*\"):\n",
        "    if filepath.suffix.lower() in image_extensions:\n",
        "        img_type = imghdr.what(filepath)\n",
        "        if img_type is None:\n",
        "            print(f\"{filepath} is not an image\")\n",
        "        elif img_type not in img_type_accepted_by_tf:\n",
        "            print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "190d2d50",
      "metadata": {
        "id": "190d2d50",
        "outputId": "a3567714-380c-401c-ff5d-75ad53f53345"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total 0 pcs image delete from Dataset\n",
            "Total 0 pcs image delete from Dataset\n",
            "Total 0 pcs image delete from Dataset\n",
            "Total 0 pcs image delete from Dataset\n",
            "Total 0 pcs image delete from Dataset\n",
            "Total 0 pcs image delete from Dataset\n",
            "Total 0 pcs image delete from Dataset\n",
            "Total 0 pcs image delete from Dataset\n",
            "Total 0 pcs image delete from Dataset\n",
            "Total 0 pcs image delete from Dataset\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import imghdr\n",
        "\n",
        "lst = ['Cat', 'Cow','Dog', 'Elephant', 'Gorilla', 'Hippo', 'Monkey', 'Panda', 'Tiger', 'Zebra']\n",
        "for i in range(10):\n",
        "    img_link=list(Path(\"Animal-Data-V2/Data-V2/Training Data/\" + lst[i]).glob(r'**/*.jpg'))\n",
        "\n",
        "    count_num=0\n",
        "    for lnk in img_link:\n",
        "        binary_img=open(lnk,'rb')\n",
        "        find_img=tf.compat.as_bytes('JFIF') in binary_img.peek(10)#The JFIF is a JPEG File Interchange Format (JFIF). It is a standard which we gauge if an image is corrupt or substandard\n",
        "        if not find_img:\n",
        "            count_num+=1\n",
        "            os.remove(str(lnk))\n",
        "    print('Total %d pcs image delete from Dataset' % count_num)\n",
        "    #this should help you delete the bad encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "720bd00b",
      "metadata": {
        "id": "720bd00b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}